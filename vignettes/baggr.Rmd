---
title: "Aggregating Average Treatment Effects with Baggr"
author: "Witold Wiecek, Rachael Meager"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{baggr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>")
library(baggr)
library(ggplot2)
baggr_schools <- baggr(schools, model = "rubin", pooling = "partial")
baggr_plot(baggr_schools)
baggr_compare(schools)
my_baggr_plot <- baggr_compare(schools)


```


_Vignette under construction (duh)_

Baggr, pronounced "bagger" or "badger" and short for Bayesian Aggregator, is a package for aggregating evidence on causal effects measured in several separate and different instances. These instances may be different studies, groups, locations or "sites" however conceptualised. We refer to these separate pieces of evidence as "groups" for the remainder of this document. When each group is a study, the user is typically doing meta-analysis, but aggregation is not limited to this case.

One of the most basic objects of interest is the average treatment effect estimated using all the evidence from all the groups. Consider the case where the evidence in each study or group is generated by comparing the outcomes of treatment and control samples in a randomized experiment. We will ignore any covariate information at the individual or group level for now.

Consider some outcome of interest $y_{ik}$ such as consumption, income or health outcomes for a household or individual $i = 1,2,...N_k$ in study group $k = 1,2....K$. Let $Y_k$ denote the $N_k$-length vector of observed outcomes from group $k$. Denote the binary indicator of treatment status by $T_{ik}$, and denote by $T_k$ the $N_k$-length vector of all treatment status indicators from group $k$. Suppose that $y_{ik}$ varies randomly around its conditional mean $\mu_k + \tau_k T_i$. In this setting $\tau_k$ is the treatment effect in group $k$. The random variation in $y_{ik}$ may be the result of sampling variation or measurement error, as in the Rubin (1981) model, or it may be the result of unmodeled heterogeneity or uncertainty in outcomes for individuals within the group. Allow the variance of the outcome variable $y_{ik}$ to vary across sites, so $\sigma_{y_k}^2$ may differ across $k$. 

# Data inputs: reported effects or full individual-level data sets

For average effects aggregation, Baggr allows 3 types of data inputs. The user may supply, within a data frame environment, any of the following:

(1) A set of estimated treatment effects $\{\hat{\tau_k}\}_{k=1}^{K}$ and their standard errors $\{\hat{se_k}\}_{k=1}^{K}$ from each study. This should be formatted as two column vectors of length $K$ within the dataframe, where $\hat{\tau_k}$ is the $k$th entry of the treatment effect vector and  $\hat{se_k}$ is the $k$th entry of the standard errors vector. 

(2) A set of both control group means and estimated treatment effects $\{\hat{\mu_k},\hat{\tau_k}\}_{k=1}^{K}$, as well as the standard errors for both $\{\hat{se}_{\mu k}, \hat{se}_{\tau k}\}_{k=1}^{K}$, for each study site This should be formatted as four vectors of length $K$ within the dataframe, analogous to the above.

(3) The full data sets from all the original studies $\{Y_k, T_k\}_{k=1}^{K}$. This should be formatted as three vectors of length $\sum_{k=1}^K N_{k}$. The $Y$ and $T$ vectors containing outcome and treatment should be generated by stacking the $K$ sites on top of one another in a dataframe. There should be a third vector of site indicators which can generally be constructed in R by first generating a $K$-length vector denoted Nk containing $(N_1, N_2..., N_K)$ and then using the R command rep(1:K, Nk) and added to the dataframe.



```{r}
```


# ATE aggregation models in baggr

Baggr currently contains two different models suitable for estimating average treatment effects [ RM Q: there is a potential confusion here. Our aggregation models always estimate an average effect of the group effects, but in the cases below, those group effects are also themselves the average treatment effects from the groups. For quantiles, we will estimate the average of the quantile effects across groups. I wonder if worth clarifying -- probably later, when the quantile models make it into this or another vignette?] Consider first the evidence aggregation model from Rubin (1981), discussed extensively in Chapter 5 of Bayesian Data Analysis by Gelman, Carlin, Rubin and Stern. This model is called "rubin" in baggr. The model consists of a hierarchical likelihood as follows:
\begin{equation}
\begin{aligned}
\hat{\tau_k} &\sim N(\tau_k, \hat{se_k}^2) \; \forall \; k \\
\tau_k &\sim N(\tau, \sigma_{\tau}^2) \; \forall \; k .
\end{aligned}
\label{rubin model}
\end{equation}
The motivation for this model structure is discussed in detail in the sources above and in Meager (2019). To complete the Bayesian model, we now need priors. Baggr has a set of default priors for each model as well as allowing the user to specify her own priors if desired (although currently the functional form of the priors cannot be changed; see discussion in next section). In the Rubin model, baggr's default priors on the hyper parameters are as follows: for $\tau$, the prior is Normal with mean 0 and variance 1000. This is a very weak prior which does little regularization as a default, centered at zero following the basic philosophical approach that causal effects should not be thought of as large unless data contains evidence to the contrary (a handwavey form of Occam's Razor). For $\sigma_{\tau}$ the prior is Uniform on an interval from zero to 10 times the simple or naive variance estimator of the vector $\{\hat{\tau_k}\}_{k=1}^{K}$ generated by the R command var().

In case you also have data on the control groups' mean outcomes and the uncertainty on those, it would make sense to augment the Rubin (1981) model to incorporate that information. Following Meager (2019), if one has access to the estimated control means  $\{\hat{\mu_k}\}^K_{k=1}$ and their standard errors $\{\hat{se}_{\mu k}\}^K_{k=1}$, one can fit a jointly Normal model on the pairs $\{\hat{\mu_k},\hat{\tau_k}\}_{k=1}^{K}$. Baggr implements the model from Meager (2019) which it calls the "mutau" model, like so:

\begin{equation}
\begin{aligned}
\hat{\tau_k} &\sim N(\tau_k, \hat{se_{\tau k}}^2) \; \forall \; k \\
\hat{\mu_k} &\sim N(\mu_k, \hat{se_{\mu k}}^2) \; \forall \; k \\
\left( \begin{array}{c}
\mu_{k}\\
\tau_{k}
\end{array} \right) 
&\sim
N\left( \left(
\begin{array}{c}
\mu\\
\tau
\end{array} \right), V \right) \; \text{where} \;V = \left[ \begin{array}{cc} \sigma^2_{\mu} & \sigma_{\tau\mu} \\ \sigma_{\tau\mu} & \sigma_{\tau}^2 \end{array} \right]\forall \; k. \\
\end{aligned}
\label{full data model}
\end{equation}

If you have only few groups, the priors on $V$ will need to be relatively strong to avoid overfitting. See Meager (2019) for more dicussion of this. [RM needs to add in the prior arguments here still.]

```{r}
```

# Running the Rubin Model in baggr

To demonstrate the Rubin model in baggr, consider the 8 schools example from Rubin (1981). In this dataset, 8 schools in the United States performed similar randomized experiments to estimate the causal effect of an SAT tutoring program on learning outcomes. We the analysts observe a dataframe of estimated treatment effects and reported standard errors, which is stored in baggr as the dataframe "schools":
```{r}
schools
```


To fit this model in Stan, having followed the installation instructions, you would then follow the instructions in https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#how-to-use-rstan. To fit the model in baggr, having followed the installation instructions and loaded the package, 
```{r eval=FALSE}
baggr_schools <- baggr(schools, model = "rubin", pooling = "partial")
```

This creates a baggr object, and you can access the underlying stanfit object by calling baggr_schools$fit. If you use the default priors, then baggr will print a message informing you of the priors it has chosen. 

If you print baggr_schools now you will see a summary of the posterior inference.  
```{r}
print(baggr_schools)
```
This is quite similar to the output you get if you run the version of the model suggested in "How to use rstan", the small difference probably arising from the different default priors. You can change the priors in baggr, although currently you cannot change the functional form of the priors. The first parameter you can change is the upper bound of the uniform prior on $\sigma_{\tau}$, called "prior_upper_sigma_tau", the second is the mean of the prior on $\tau$ itself called "prior_tau_mean", the third is the scale (standard deviation) of the prior on $\tau$ itself called "prior_tau_scale". Here I have changed all three as an example (at this stage in baggr if you want to alter one you must provide the full vector). 
```{r eval=FALSE}
baggr(schools, "rubin", prior = c("prior_upper_sigma_tau" = 10000, "prior_tau_mean" = -10, "prior_tau_scale" = 100))
print(baggr_schools)
```

<!-- #[WORKING SECTION Suppose you have the full inividual-level dataset for all groups (case 3 above) but still wish to run the Rubin model: baggr can do this automatically, you do not need to manually estimate the group-specific effects and standard errors yourself. To see how it works, check out the microcredit dataset analysed in Meager (2019) which is stored in baggr as the dataframe "microcredit". Have a look at the tail of the dataframe, which tells you that these households are from the "Tarozzi" et al study group (the Ethiopia trial), for which we have expenditures, revenue and profit data, as well as the treatment indicator. -->
<!-- # ```{r} -->
<!-- # tail(microcredit) -->
<!-- # ``` -->
<!-- # Baggr will only understand the 3 types of formatting described above, and while we have already stacked this dataset, we now need to choose a single outcome to focus on.  ] -->


# Understanding and criticising baggr model performance

Baggr models are run in Stan, and the fit and results need to be checked, understood and criticised as you would any stan model or indeed any MCMC model fitting exercise. **You must pay attention to printed warnings about the Rhat criterion: if you see a warning that Rhat statistic exceeds 1.05 for any parameter, you MUST NOT use the results for inference.** This warning means the MCMC chains have not converged, and it is exceedingly unlikely that the "posterior inference" printed out corresponds to anything close to the true posterior implied by your model and data. **If you use results from which the Rhat statistic exceeds 1.05 YOUR INFERENCE WILL BE WRONG.**

If you see this warning, try re-running the model with the option "iter" set to a large number such as 10,000, as below. It is also good practice to run many chains, such as 8 rather than the default 4, to have a greater chance to detect pathological MCMC behaviour. You do this by passing baggr the stan arguments "iter = 10000" and "chains = 8", like so:
```{r eval=FALSE}
baggr_schools <- baggr(schools, model = "rubin", pooling = "partial", iter = 10000, chains = 8)
```

Other warnings you may see involve "divergent transitions". While not as serious as Rhat, this can signal problems with the model. As the stan message that you will see suggests, try adjusting adapt_delta above 0.8. You cannot pass this parameter directly to stan and thus you cannot pass it directly to baggr, so instead you must pass the argument "control = list(adapt_delta = 0.99)" to set adapt_delta to 0.99. 

# Plotting and Model Comparison in baggr

The first step to understanding the model is to plot the posterior inference. Baggr has several automatic plot functions using the command baggr_plot() which calls bayesplot under the hood.  This command takes in a baggr object as its argument and automatically generates a plot of the posterior mean and central 95\% posterior intervals of the effects in each group. Here we have the plot for the 8 schools Rubin model, and I've opted not to order by effect size because I prefer alphabetical.
```{r }
baggr_plot(baggr_schools, order = FALSE)
```

The second step to understanding the model is to compare it to other models we could have fit: this can be done automatically in baggr using the command baggr_compare. The default Rubin model (which we have selected explicitly above) is partial pooling. If you run the code below, baggr will fit the full pooling, no pooling and partial pooling versions of the Rubin model and print the results of each for you in the console:

```{r eval=FALSE}
baggr_compare(schools)
```

The baggr_compare command also produces an automatic comparison plot made by calling ggplot2 under the hood, in a format we've tweaked in ggplot2 to look pretty (we think). Because the output object of baggr_compare is a ggplot object you can edit it further yourself and built on it as you would any ggplot object. For example, the default title for the plot is just "mean", so here I've changed it to be more descriptive:

```{r eval=FALSE}
my_baggr_plot <- baggr_compare(schools)
```


```{r fig.width=7, fig.height=4}
my_baggr_plot$plot + ggtitle("8 Schools Model Comparison")
```

# Cross-Validation in baggr

Baggr has automated leave-one-out cross validation for its models, where the "one" always refers to one group. This naturally corresponds to the question of how much any one group has contributed to the overall inference, which is often pertinent. Therefore, if you have K groups, using the loocv() baggr command entails running your model of choice K times. Be aware that this may take a while even for simple models. The loocv() baggr command takes in a data argument, the option for whether to return all the models or just the summary statistics, and then the usual baggr arguments such as which model and what kind of pooling. For example the code below does leave-one-school-out cross-validation on the Rubin model with partial pooling.
```{r eval = TRUE}
loocv(schools, return_models = FALSE, "rubin", pooling = "partial")
```

This returns a [RM Q: WW WHAT IS THE FIRST OBJECT RETURNED? JUST A SINGLE NUMBER] as well as a dataframe of length K with the posterior mean of the overall average treatment effect $\tau$ for each of the CV exercises (K in total) and the corresponding log posterior densities of the model for that run. This dataframe can then be used to examine or compute the variation in the inference on $\tau$ in the absence of each group.
